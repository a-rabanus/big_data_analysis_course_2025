{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b976ebf",
   "metadata": {},
   "source": [
    "# Image classifier - complete pipeline\n",
    "\n",
    "## Approach:\n",
    "\n",
    "`find relevant image characteristics` $\\rightarrow$ `create feature vector creation pipeline` $\\rightarrow$ `iterate through dataset` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a1d2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df61467",
   "metadata": {},
   "source": [
    "# Loading and displaying images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a449504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.images = []\n",
    "        self.downscaled_images = []\n",
    "        \n",
    "    def load_images(self):\n",
    "        self.images = []\n",
    "        for filename in os.listdir(self.directory):\n",
    "            filepath = os.path.join(self.directory, filename)\n",
    "            if os.path.isfile(filepath):\n",
    "                img = cv2.imread(filepath)\n",
    "                if img is not None:\n",
    "                    self.images.append((filename, img))\n",
    "    \n",
    "    def downscale_images(self, factor=0.01):\n",
    "        self.downscaled_images = []\n",
    "        for filename, img in self.images:\n",
    "            height, width = img.shape[:2]\n",
    "            new_size = (int(width * factor), int(height * factor))\n",
    "            downscaled_img = cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
    "            self.downscaled_images.append((filename, downscaled_img))\n",
    "\n",
    "class ImageVisualizer:\n",
    "    @staticmethod\n",
    "    def display_image(images, img_id=None):\n",
    "        if img_id is None:\n",
    "            img_id = random.randint(0, len(images)-1)\n",
    "        filename, img = images[img_id]\n",
    "        plt.figure()\n",
    "        plt.title(filename)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def show_similar_images(original_images, similar_images_data, title=\"\", show_plot=False, save_plot=False):\n",
    "        image_dict = {filename: img for filename, img in original_images}\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "        if len(similar_images_data) < 5:\n",
    "            axes = axes.flat[:len(similar_images_data)]\n",
    "        \n",
    "        for ax, (filename, _, _, similarity) in zip(axes, similar_images_data[:5]):\n",
    "            img = image_dict[filename]\n",
    "            ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))s\n",
    "            ax.set_title(f\"{filename}\\nSimilarity: {similarity:.2f}\")\n",
    "            ax.axis('off')\n",
    "        fig.suptitle(title)\n",
    "        plt.tight_layout()\n",
    "        if save_plot: plt.savefig(f\"{title.replace(' ', '_')}_comparison.png\")\n",
    "        if show_plot: plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3114f0b",
   "metadata": {},
   "source": [
    "# Image Characteristics for feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8dd523",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \"\"\"\n",
    "    A modular, object-oriented feature extraction class for image analysis.\n",
    "\n",
    "    This class allows dynamic and extensible extraction of a wide variety of image features\n",
    "    from a given image. It supports selective feature computation, meaning you can\n",
    "    request only the features you need, and the resulting feature vector will adapt accordingly,\n",
    "    while maintaining a consistent ordering.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    filename : str\n",
    "        The name or path of the image file (used for identification/logging purposes).\n",
    "    image : np.ndarray\n",
    "        The image data as a NumPy array (BGR format, typically from cv2.imread).\n",
    "    feature_functions : dict\n",
    "        A mapping of feature names to their corresponding extraction methods.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    extract_features(features: list[str]) -> np.ndarray\n",
    "        Extracts the selected features from the image and returns a flattened NumPy array\n",
    "        of shape (num_features, ). Each feature can contribute a scalar or a vector, and\n",
    "        all are concatenated in the order requested.\n",
    "\n",
    "    Design Rationale:\n",
    "    -----------------\n",
    "    - **Flexibility**: Users can specify exactly which features to extract by passing a list of feature names.\n",
    "    - **Extensibility**: New features can be added simply by writing a new method and registering it\n",
    "      in the `feature_functions` dictionary. This avoids modifying core logic and encourages modular design.\n",
    "    - **Consistency**: Regardless of the number or type of features requested, the output is always\n",
    "      a flat NumPy array, enabling compatibility with machine learning pipelines or downstream analysis.\n",
    "    - **Encapsulation**: Image handling and feature logic are neatly encapsulated within the class.\n",
    "\n",
    "    Example Usage:\n",
    "    --------------\n",
    "    >>> import cv2\n",
    "    >>> img = cv2.imread(\"example.jpg\")\n",
    "    >>> extractor = FeatureExtractor(\"example.jpg\", img)\n",
    "    >>> features = extractor.extract_features([\"mean_intensity\", \"edge_density\", \"color_histogram\"])\n",
    "    >>> print(features.shape)  # Output: (num_features, )\n",
    "\n",
    "    Adding a New Feature:\n",
    "    ---------------------\n",
    "    1. Define a new method following the `_feature_name(self)` naming pattern.\n",
    "       The method should return a scalar or 1D/2D array-like output.\n",
    "       \n",
    "       Example:\n",
    "       >>> def _texture_entropy(self):\n",
    "       >>>     from skimage.measure import shannon_entropy\n",
    "       >>>     return shannon_entropy(self.image)\n",
    "\n",
    "    2. Register the new method in `self.feature_functions` inside `__init__`:\n",
    "       >>> self.feature_functions[\"texture_entropy\"] = self._texture_entropy\n",
    "\n",
    "    3. Now, you can request \"texture_entropy\" as part of your feature list.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_data):\n",
    "        self.filename, self.image = image_data # contains filename, image\n",
    "        self.feature_functions = {\n",
    "            \"extract_dominant_colors\": self._extract_dominant_colors_kmeans,\n",
    "            \"extract_dominant_colors_fingerpring\": self._extract_dominant_colors_fingerprint,\n",
    "            \"mean_intensity\": self._mean_intensity,\n",
    "            \"edge_density\": self._edge_density,\n",
    "            \"color_histogram\": self._color_histogram,\n",
    "        }\n",
    "        pass\n",
    "\n",
    "    def generate_feature_vector(self, features: list[str]) -> np.ndarray:\n",
    "        extracted = []\n",
    "\n",
    "        for feature_name in features:\n",
    "            if feature_name not in self.feature_functions:\n",
    "                raise ValueError(f\"Feature '{feature_name}' not implemented.\")\n",
    "            \n",
    "            feature_value = self.feature_functions[feature_name]()\n",
    "            feature_value = np.ravel(feature_value)  # Ensure flat output\n",
    "            extracted.append(feature_value)\n",
    "\n",
    "        return np.concatenate(extracted)\n",
    "\n",
    "    # ===== feature extraction methods =====\n",
    "  \n",
    "    def _mean_intensity(self):\n",
    "        return np.mean(self.image)\n",
    "\n",
    "    def _edge_density(self):\n",
    "        edges = cv2.Canny(self.image, 100, 200)\n",
    "        return np.sum(edges > 0) / edges.size\n",
    "\n",
    "    def _color_histogram(self, bins=8):\n",
    "        chans = cv2.split(self.image)\n",
    "        features = []\n",
    "        for chan in chans:\n",
    "            hist = cv2.calcHist([chan], [0], None, [bins], [0, 256])\n",
    "            hist = cv2.normalize(hist, hist).flatten()\n",
    "            features.extend(hist)\n",
    "        return np.array(features)\n",
    "    \n",
    "    def _extract_dominant_colors_kmeans(self):\n",
    "        pass\n",
    "\n",
    "    def _extract_dominant_colors_fingerprint(self):\n",
    "        pass\n",
    "\n",
    "    def _fft_fingerprinting(self):\n",
    "        pass\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
