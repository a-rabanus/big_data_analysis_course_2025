{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b976ebf",
   "metadata": {},
   "source": [
    "# Image classifier - complete pipeline\n",
    "\n",
    "## Approach:\n",
    "\n",
    "`find relevant image characteristics` $\\rightarrow$ `create feature vector creation pipeline` $\\rightarrow$ `iterate through dataset` \n",
    "\n",
    "The pipeline we are trying to implement handles images using out `ImageProcessor` and passes them through out `FeatureExtractor` which in turn returns a feature vector composed of our different analysis methods. This way we are not constraining ourselves to a rigid processing system that can only take a certain type of feature vector.\n",
    "\n",
    "For displaying images we're using a `ImageVisualizer` tool.\n",
    "\n",
    "Our feature vector is a `(n,) numpy array` (`n` is the number of features extracted) that can later be added to some database or hashed for quick lookup of similar images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1d2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "import os\n",
    "import sqlite3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df61467",
   "metadata": {},
   "source": [
    "# Loading and displaying images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a449504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.images = []\n",
    "        self.downscaled_images = []\n",
    "        \n",
    "    def load_images(self):\n",
    "        self.images = []\n",
    "        for filename in os.listdir(self.directory):\n",
    "            filepath = os.path.join(self.directory, filename)\n",
    "            if os.path.isfile(filepath):\n",
    "                img = cv2.imread(filepath)\n",
    "                if img is not None:\n",
    "                    self.images.append((filename, img))\n",
    "    \n",
    "    def downscale_images(self, factor=0.01):\n",
    "        self.downscaled_images = []\n",
    "        for filename, img in self.images:\n",
    "            height, width = img.shape[:2]\n",
    "            new_size = (int(width * factor), int(height * factor))\n",
    "            downscaled_img = cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
    "            self.downscaled_images.append((filename, downscaled_img))\n",
    "\n",
    "class ImageVisualizer:\n",
    "    @staticmethod\n",
    "    def display_image(images, img_id=None):\n",
    "        if img_id is None:\n",
    "            img_id = random.randint(0, len(images)-1)\n",
    "        filename, img = images[img_id]\n",
    "        plt.figure()\n",
    "        plt.title(filename)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def show_similar_images(original_images, similar_images_data, title=\"\", show_plot=False, save_plot=False):\n",
    "        image_dict = {filename: img for filename, img in original_images}\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "        if len(similar_images_data) < 5:\n",
    "            axes = axes.flat[:len(similar_images_data)]\n",
    "        \n",
    "        for ax, (filename, _, _, similarity) in zip(axes, similar_images_data[:5]):\n",
    "            img = image_dict[filename]\n",
    "            ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            ax.set_title(f\"{filename}\\nSimilarity: {similarity:.2f}\")\n",
    "            ax.axis('off')\n",
    "        fig.suptitle(title)\n",
    "        plt.tight_layout()\n",
    "        if save_plot: plt.savefig(f\"{title.replace(' ', '_')}_comparison.png\")\n",
    "        if show_plot: plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3114f0b",
   "metadata": {},
   "source": [
    "# Image Characteristics for feature vector\n",
    "\n",
    "Out `FeatureExtractor` module concept is designes modularly, so that any image processing function can be added later on in the process so that the pipeline built around the extraction of image features doesn't have to be touched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8dd523",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \"\"\"\n",
    "    A modular, object-oriented feature extraction class for image analysis.\n",
    "\n",
    "    This class allows dynamic and extensible extraction of a wide variety of image features\n",
    "    from a given image. It supports selective feature computation, meaning you can\n",
    "    request only the features you need, and the resulting feature vector will adapt accordingly,\n",
    "    while maintaining a consistent ordering.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    filename : str\n",
    "        The name or path of the image file (used for identification/logging purposes).\n",
    "    image : np.ndarray\n",
    "        The image data as a NumPy array (BGR format, typically from cv2.imread).\n",
    "    feature_functions : dict\n",
    "        A mapping of feature names to their corresponding extraction methods.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    extract_features(features: list[str]) -> np.ndarray\n",
    "        Extracts the selected features from the image and returns a flattened NumPy array\n",
    "        of shape (num_features, ). Each feature can contribute a scalar or a vector, and\n",
    "        all are concatenated in the order requested.\n",
    "\n",
    "    Design Rationale:\n",
    "    -----------------\n",
    "    - **Flexibility**: Users can specify exactly which features to extract by passing a list of feature names.\n",
    "    - **Extensibility**: New features can be added simply by writing a new method and registering it\n",
    "      in the `feature_functions` dictionary. This avoids modifying core logic and encourages modular design.\n",
    "    - **Consistency**: Regardless of the number or type of features requested, the output is always\n",
    "      a flat NumPy array, enabling compatibility with machine learning pipelines or downstream analysis.\n",
    "    - **Encapsulation**: Image handling and feature logic are neatly encapsulated within the class.\n",
    "\n",
    "    Example Usage:\n",
    "    --------------\n",
    "    >>> import cv2\n",
    "    >>> img = cv2.imread(\"example.jpg\")\n",
    "    >>> extractor = FeatureExtractor(\"example.jpg\", img)\n",
    "    >>> features = extractor.extract_features([\"mean_intensity\", \"edge_density\", \"color_histogram\"])\n",
    "    >>> print(features.shape)  # Output: (num_features, )\n",
    "\n",
    "    Adding a New Feature:\n",
    "    ---------------------\n",
    "    1. Define a new method following the `_feature_name(self)` naming pattern.\n",
    "       The method should return a scalar or 1D/2D array-like output.\n",
    "       \n",
    "       Example:\n",
    "       >>> def _texture_entropy(self):\n",
    "       >>>     from skimage.measure import shannon_entropy\n",
    "       >>>     return shannon_entropy(self.image)\n",
    "\n",
    "    2. Register the new method in `self.feature_functions` inside `__init__`:\n",
    "       >>> self.feature_functions[\"texture_entropy\"] = self._texture_entropy\n",
    "\n",
    "    3. Now, you can request \"texture_entropy\" as part of your feature list.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, images, img_id):\n",
    "        self.filename, self.image = images[img_id] # contains filename, image\n",
    "        self.feature_functions = {\n",
    "            \"extract_dominant_colors\": self._extract_dominant_colors_kmeans,\n",
    "            \"extract_dominant_colors_fingerpring\": self._extract_dominant_colors_fingerprint,\n",
    "            \"mean_intensity\": self._mean_intensity,\n",
    "            \"edge_density\": self._edge_density,\n",
    "            \"color_histogram\": self._color_histogram,\n",
    "            \"fft_fingerpring\": self._fft_fingerprinting\n",
    "        }\n",
    "        pass\n",
    "\n",
    "    def generate_feature_vector(self, features: list[str]) -> np.ndarray:\n",
    "        extracted = {}\n",
    "\n",
    "        for feature_name in features:\n",
    "            if feature_name not in self.feature_functions:\n",
    "                raise ValueError(f\"Feature '{feature_name}' not implemented.\")\n",
    "            \n",
    "            feature_value = self.feature_functions[feature_name]()\n",
    "            extracted[feature_name] = feature_value\n",
    "\n",
    "        return extracted\n",
    "\n",
    "    # ===== feature extraction methods =====\n",
    "    \n",
    "    def _extract_dominant_colors_kmeans(self):\n",
    "        pass\n",
    "\n",
    "    def _extract_dominant_colors_fingerprint(self):\n",
    "        pass\n",
    "\n",
    "    def _mean_intensity(self):\n",
    "        return np.mean(self.image)\n",
    "\n",
    "    def _edge_density(self):\n",
    "        edges = cv2.Canny(self.image, 100, 200)\n",
    "        return np.sum(edges > 0) / edges.size\n",
    "\n",
    "    def _color_histogram(self, bins=8):\n",
    "        \"\"\"Returns histogram of number of bins for each color\n",
    "        output: numpy array shape (bins*3, )\n",
    "        \"\"\"\n",
    "        chans = cv2.split(self.image)\n",
    "        features = []\n",
    "        for chan in chans:\n",
    "            hist = cv2.calcHist([chan], [0], None, [bins], [0, 256])\n",
    "            hist = cv2.normalize(hist, hist).flatten()\n",
    "            features.extend(hist)\n",
    "        return np.array(features)\n",
    "    \n",
    "    def _fft_fingerprinting(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d90c0",
   "metadata": {},
   "source": [
    "# Database management class\n",
    "\n",
    "This version of the `DatabaseManager` will infer column names and types from the features used. It determines the SQL data type by checking which type is located in the dictionary of extracted features and build the queries respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc21277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseManager:\n",
    "    \"\"\"\n",
    "    Manages SQLite database operations for storing and retrieving image features.\n",
    "    This class dynamically creates table columns based on the feature names used while extracting them.\n",
    "    \"\"\"\n",
    "    def __init__(self, db_path):\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        pass\n",
    "\n",
    "    def _get_sql_type(self, value):\n",
    "        \"\"\"\n",
    "        Looks at the data type of the feature\n",
    "        Infers an appropriate SQL datatype from the python value\"\"\"\n",
    "        if isinstance(value, (np.ndarray, list)):\n",
    "            return \"TEXT\" # makes numpy arrays and lists as text for JSON serialized arrays later\n",
    "        if isinstance(value, (int, np.integer)):\n",
    "            return \"INTEGER\" # checks for int, specifies INTEGER for db\n",
    "        if isinstance(value, (float, np.floating)):\n",
    "            return \"REAL\"\n",
    "        return \"TEXT\" # default value if no other type is found\n",
    "\n",
    "    def create_table(self, features_to_extract, sample_feature_dict):\n",
    "        \"\"\"\n",
    "        Creates the 'features' table if it doens't already exist\n",
    "        Looks at dictionary of extracted features to create the cols and specify their datatype \n",
    "        \"\"\"\n",
    "        columns_sql = [\"id INTEGER PRIMARY KEY AUTOINCREMENT\", \"filename TEXT UNIQUE\"]\n",
    "        for feature_name in features_to_extract:\n",
    "            if feature_name in sample_feature_dict:\n",
    "                sample_value = sample_feature_dict[feature_name]\n",
    "                sql_type = self._get_sql_type(sample_value) # calls _get_sql_type function to know whihch datatype to specify when creating the table\n",
    "                # Column name for SQL\n",
    "                safe_feature_name = ''.join(c for c in feature_name if c.isalnum() or c == \"_\")\n",
    "                columns_sql.append(f\"{safe_feature_name} {sql_type}\")\n",
    "        \n",
    "        create_table_query = f\"CREATE TABLE IF NOT EXISTS features ({\", \".join(columns_sql)})\"\n",
    "\n",
    "        self.cursor.execute(create_table_query)\n",
    "        self.conn.commit()\n",
    "        print(\"Database and table are ready\")\n",
    "        pass\n",
    "\n",
    "    def insert_feature_vector(self, filename, feature_dict):\n",
    "        \"\"\"\n",
    "        Dynamically inserts any image's features into the database\n",
    "        It handles column names and values serialization automatically.        \n",
    "        \"\"\"\n",
    "        column_names = [\"filename\"] + list(feature_dict.keys())\n",
    "\n",
    "        values = [filename]\n",
    "        for value in feature_dict.values():\n",
    "            if isinstance(value, np.ndarray):\n",
    "                values.append(json.dumps(value.tolist())) # serialize numpy arrays\n",
    "            else:\n",
    "                values.append(value)\n",
    "        \n",
    "        placeholders = \", \".join([\"?\"] * len(column_names))\n",
    "        # ensure column names are sanitized for safety\n",
    "        safe_column_names = \", \".join(\"\".join(c for c in name if c.isalnum() or c == \"_\") for name in column_names)\n",
    "\n",
    "        insert_query = f\"INSERT INTO features ({safe_column_names}) VALUES ({placeholders})\"\n",
    "        \n",
    "        try:\n",
    "            self.cursor.execute(insert_query, tuple(values))\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(f\"Features for '{filename}' already exist in the database. Skipping.\")\n",
    "        \n",
    "    def close(self):\n",
    "        \"\"\"Close the db connectin\"\"\"\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "            print(\"Database connection is closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e911721",
   "metadata": {},
   "source": [
    "# Execution\n",
    "\n",
    "The following code block creates an SQLite database from the images located in the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf54e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 108 images to process\n",
      "Generating samplel features to define database schema...\n",
      "Database and table are ready\n",
      "Processed and stored features for image 1/108: 20250328_101537.jpg\n",
      "Processed and stored features for image 2/108: 20250328_101618.jpg\n",
      "Processed and stored features for image 3/108: 20250328_101653.jpg\n",
      "Processed and stored features for image 4/108: 20250328_101657.jpg\n",
      "Processed and stored features for image 5/108: 20250328_101820.jpg\n",
      "Processed and stored features for image 6/108: 20250328_101852.jpg\n",
      "Processed and stored features for image 7/108: 20250328_101935.jpg\n",
      "Processed and stored features for image 8/108: 20250328_102018.jpg\n",
      "Processed and stored features for image 9/108: 20250328_102144.jpg\n",
      "Processed and stored features for image 10/108: 20250328_102238.jpg\n",
      "Processed and stored features for image 11/108: 20250328_102309.jpg\n",
      "Processed and stored features for image 12/108: 20250328_102425.jpg\n",
      "Processed and stored features for image 13/108: 20250328_102530.jpg\n",
      "Processed and stored features for image 14/108: 20250328_102648.jpg\n",
      "Processed and stored features for image 15/108: 20250328_102904.jpg\n",
      "Processed and stored features for image 16/108: 20250328_103010(1).jpg\n",
      "Processed and stored features for image 17/108: 20250328_103010.jpg\n",
      "Processed and stored features for image 18/108: 20250328_103155.jpg\n",
      "Processed and stored features for image 19/108: 20250328_103337.jpg\n",
      "Processed and stored features for image 20/108: 20250328_103502.jpg\n",
      "Processed and stored features for image 21/108: 20250328_103545.jpg\n",
      "Processed and stored features for image 22/108: 20250328_103647.jpg\n",
      "Processed and stored features for image 23/108: 20250328_103720.jpg\n",
      "Processed and stored features for image 24/108: 20250328_103803.jpg\n",
      "Processed and stored features for image 25/108: 20250328_104041.jpg\n",
      "Processed and stored features for image 26/108: 20250328_104134.jpg\n",
      "Processed and stored features for image 27/108: 20250328_104203.jpg\n",
      "Processed and stored features for image 28/108: 20250328_104246.jpg\n",
      "Processed and stored features for image 29/108: campus.jpg\n",
      "Processed and stored features for image 30/108: IMG_20250328_101716372.jpg\n",
      "Processed and stored features for image 31/108: IMG_20250328_102052530.jpg\n",
      "Processed and stored features for image 32/108: IMG_20250328_102141782.jpg\n",
      "Processed and stored features for image 33/108: IMG_20250328_102429136.jpg\n",
      "Processed and stored features for image 34/108: IMG_20250328_102659326.jpg\n",
      "Processed and stored features for image 35/108: IMG_20250328_102856727.jpg\n",
      "Processed and stored features for image 36/108: IMG_2589.jpeg\n",
      "Processed and stored features for image 37/108: IMG_2590.jpeg\n",
      "Processed and stored features for image 38/108: IMG_2592.jpeg\n",
      "Processed and stored features for image 39/108: IMG_2593.jpeg\n",
      "Processed and stored features for image 40/108: IMG_2594.jpeg\n",
      "Processed and stored features for image 41/108: IMG_2595.jpeg\n",
      "Processed and stored features for image 42/108: IMG_2597.jpeg\n",
      "Processed and stored features for image 43/108: IMG_2598.jpeg\n",
      "Processed and stored features for image 44/108: IMG_2599.jpeg\n",
      "Processed and stored features for image 45/108: IMG_2600.jpeg\n",
      "Processed and stored features for image 46/108: IMG_3331.jpeg\n",
      "Processed and stored features for image 47/108: IMG_3332.jpeg\n",
      "Processed and stored features for image 48/108: IMG_3339.jpeg\n",
      "Processed and stored features for image 49/108: IMG_3343.jpeg\n",
      "Processed and stored features for image 50/108: IMG_3346.jpeg\n",
      "Processed and stored features for image 51/108: IMG_3361.jpeg\n",
      "Processed and stored features for image 52/108: IMG_3367.jpeg\n",
      "Processed and stored features for image 53/108: IMG_3370.jpeg\n",
      "Processed and stored features for image 54/108: IMG_3378.jpeg\n",
      "Processed and stored features for image 55/108: IMG_3660.jpeg\n",
      "Processed and stored features for image 56/108: IMG_3661.jpeg\n",
      "Processed and stored features for image 57/108: IMG_3662.jpeg\n",
      "Processed and stored features for image 58/108: IMG_3663.jpeg\n",
      "Processed and stored features for image 59/108: IMG_3664.jpeg\n",
      "Processed and stored features for image 60/108: IMG_3665.jpeg\n",
      "Processed and stored features for image 61/108: IMG_3666.jpeg\n",
      "Processed and stored features for image 62/108: IMG_3667.jpeg\n",
      "Processed and stored features for image 63/108: IMG_3668.jpeg\n",
      "Processed and stored features for image 64/108: IMG_3669.jpeg\n",
      "Processed and stored features for image 65/108: IMG_3670.jpeg\n",
      "Processed and stored features for image 66/108: IMG_3672.jpeg\n",
      "Processed and stored features for image 67/108: IMG_3673.jpeg\n",
      "Processed and stored features for image 68/108: IMG_3674.jpeg\n",
      "Processed and stored features for image 69/108: IMG_3675.jpeg\n",
      "Processed and stored features for image 70/108: IMG_3676.jpeg\n",
      "Processed and stored features for image 71/108: IMG_3677.jpeg\n",
      "Processed and stored features for image 72/108: IMG_3678.jpeg\n",
      "Processed and stored features for image 73/108: IMG_3679.jpeg\n",
      "Processed and stored features for image 74/108: IMG_3684.jpeg\n",
      "Processed and stored features for image 75/108: IMG_7377.jpeg\n",
      "Processed and stored features for image 76/108: IMG_7378.jpeg\n",
      "Processed and stored features for image 77/108: IMG_7379.jpeg\n",
      "Processed and stored features for image 78/108: IMG_7380.jpeg\n",
      "Processed and stored features for image 79/108: IMG_7381.jpeg\n",
      "Processed and stored features for image 80/108: IMG_7382.jpeg\n",
      "Processed and stored features for image 81/108: IMG_7383.jpeg\n",
      "Processed and stored features for image 82/108: IMG_7385.jpeg\n",
      "Processed and stored features for image 83/108: PXL_20250328_091211856.jpg\n",
      "Processed and stored features for image 84/108: PXL_20250328_091519659.jpg\n",
      "Processed and stored features for image 85/108: PXL_20250328_091524785.jpg\n",
      "Processed and stored features for image 86/108: PXL_20250328_091540882.jpg\n",
      "Processed and stored features for image 87/108: PXL_20250328_091841641.MP.jpg\n",
      "Processed and stored features for image 88/108: PXL_20250328_091904670.jpg\n",
      "Processed and stored features for image 89/108: PXL_20250328_091905752.jpg\n",
      "Processed and stored features for image 90/108: PXL_20250328_091916775.jpg\n",
      "Processed and stored features for image 91/108: PXL_20250328_091953009.MP.jpg\n",
      "Processed and stored features for image 92/108: PXL_20250328_092029975.jpg\n",
      "Processed and stored features for image 93/108: PXL_20250328_092316699.jpg\n",
      "Processed and stored features for image 94/108: PXL_20250328_092324163.jpg\n",
      "Processed and stored features for image 95/108: PXL_20250328_092432391.jpg\n",
      "Processed and stored features for image 96/108: PXL_20250328_092442823.jpg\n",
      "Processed and stored features for image 97/108: PXL_20250328_092516347.jpg\n",
      "Processed and stored features for image 98/108: PXL_20250328_092712915.jpg\n",
      "Processed and stored features for image 99/108: PXL_20250328_092713987.jpg\n",
      "Processed and stored features for image 100/108: PXL_20250328_092715115.jpg\n",
      "Processed and stored features for image 101/108: PXL_20250328_092717880.jpg\n",
      "Processed and stored features for image 102/108: PXL_20250328_092831782.jpg\n",
      "Processed and stored features for image 103/108: PXL_20250328_092848715.jpg\n",
      "Processed and stored features for image 104/108: PXL_20250328_092911984.jpg\n",
      "Processed and stored features for image 105/108: PXL_20250328_092935476.jpg\n",
      "Processed and stored features for image 106/108: PXL_20250328_093128885.jpg\n",
      "Processed and stored features for image 107/108: PXL_20250501_175710911.jpg\n",
      "Processed and stored features for image 108/108: PXL_20250501_175713712.jpg\n",
      "Database connection is closed.\n",
      "\n",
      "Feature extraction and storage complete.\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL CONSTANTS\n",
    "DIR = r\"C:\\Users\\anton\\OneDrive\\Documents\\HSD\\sem4\\DAISY_2025_images_for_bigdata\"\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '12'  # Set to your actual core count\n",
    "\n",
    "\n",
    "testing_id = 1\n",
    "features_to_extract = [\n",
    "    \"mean_intensity\",\n",
    "    \"edge_density\",\n",
    "    \"color_histogram\"\n",
    "]\n",
    "\n",
    "features_as_string = \"-\"\n",
    "for i in range(len(features_to_extract)):\n",
    "    features_as_string += features_to_extract[i]\n",
    "    if i+1 == len(features_to_extract):\n",
    "        pass\n",
    "    else:\n",
    "        features_as_string += \"-\" \n",
    "\n",
    "db_name= f\"image_features_with{features_as_string}.db\"\n",
    "\n",
    "\n",
    "processor = ImageProcessor(DIR)\n",
    "db_manager = DatabaseManager(db_name)\n",
    "visualizer = ImageVisualizer()\n",
    "\n",
    "\n",
    "# load images and downscale for faster processing\n",
    "processor.load_images()\n",
    "processor.downscale_images(factor=0.01)\n",
    "images_to_process = processor.downscaled_images\n",
    "print(f\"Found {len(images_to_process)} images to process\")\n",
    "\n",
    "\n",
    "# create database dynamically\n",
    "if images_to_process:\n",
    "    # generate a sample feature dictinary from the first image to define DB Schema\n",
    "    print(\"Generating samplel features to define database schema...\")\n",
    "    sample_extractor = FeatureExtractor(images_to_process, 0)\n",
    "    sample_features = sample_extractor.generate_feature_vector(features_to_extract)\n",
    "\n",
    "    # create table dynamically based on schema\n",
    "    db_manager.create_table(features_to_extract, sample_features)\n",
    "else:\n",
    "    print(\"No images found to process\")\n",
    "    # keine ahnung wie man das dann debugd hahah\n",
    "\n",
    "\n",
    "# feature extraction and storage\n",
    "try:\n",
    "    if images_to_process:\n",
    "        total_iamges = len(images_to_process)\n",
    "        for i in range(total_iamges):\n",
    "            filename, _ = images_to_process[i]\n",
    "\n",
    "            # initialize extractor for the current image\n",
    "            extractor = FeatureExtractor(images_to_process, i)\n",
    "\n",
    "            # generate feature dict\n",
    "            feature_dict = extractor.generate_feature_vector(features_to_extract)\n",
    "\n",
    "            # insert the features to the db\n",
    "            db_manager.insert_feature_vector(filename, feature_dict)\n",
    "\n",
    "            print(f\"Processed and stored features for image {i+1}/{total_iamges}: {filename}\")\n",
    "finally:\n",
    "    db_manager.close()\n",
    "\n",
    "print(\"\\nFeature extraction and storage complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d069964",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32829ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
